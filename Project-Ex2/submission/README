dans
Dan Shumayev (207050691)
EX: 2

FILES:
README - This file.
Makefile - Build file, the default rule makes the entire library.
uthreads.h/cpp       - The provided thread library interface, implemented
                       by invoking various methods of the Scheduler singleton.
Scheduler.h/cpp - The main module managing the library threads. This is a singleton class that.
thread.h/cpp - Representing a user-thread library, containing some of threads' information
               such as its id, env and stack.
uthread_utilities.h/cpp   - Utility functionality like timer masking and typedef's.
uthread_exception.h/cpp     - Thread library error-related information.

REMARKS:

- All library functions (except the simple getters) are masked,
  this was implemented by the 'SigGuard' class which uses the
  RAII idiom (similar to lock_guard) to mask the function's scope,
  except for the case of the preempt alarm handler, which was
  automatically masked due to 'sigaction' behavior

- All library functions+signal handler are guarded against exceptions, via the 'handleExceptions' function, this is done
  to catch C++ style allocation exceptions (that may occur when allocating threads or moving them between data
  structures) to 'system errors' as defined in the exercise. Besides that, most
  error handling is done manually, using the 'systemError' and 'threadLibraryError' functions.

- Deletion of the current thread requires some trickery, because doing so in the stack frame
  of the current thread is undefined
  One could think to do so right after sigsetjmp == 0, but this doesn't handle the case where we jump to a thread in
  the first time. One could so right before sigsetjmp, but again, this function might happen to accidentally allocate
  memory on the current stack(marked as free).
  Therefore, I've opted to deal with this by killing it from another thread, at the earliest possible time
  (next manual thread library call/next preemption)

ANSWERS:

1. Question:
   Describe one general use of user-level threads and explain why they're a reasonable choice for your example.

   Answer:
   Rendering of animation is massively parallel as each frame can be
   rendered independently to others -- meaning that 10's or 100's of computers can be
   chained together to help out.

   Since we might have thousands of such frames (threads), it would be wasteful to
   map each frame to a kernel thread as both the memory overhead and context switches
   would be too large.

2. Pros and cons of using processes rather than kernel-level threads for Google Chrome app:
   * Pros:
   + Protection by isolation: In case of surfing a website that exploits a vulnerability of Chrome's browser,
                              the attacker may leak sensitive information laying on other sessions invoked by
                              Chrome's browser. If Google Chrome's app uses only 1 process (multi-threaded),
                              this information leakage would be something easy to be done, whereas in the case of
                              a different process for each Chrome's tab, then not only he'd have to exploit the
                              browser's vuln, but also exploit the OS virtual memory - which would be much harder.

  + Performance: A Chrome's tab might crash or be suspended for a while. In this case, unless using multi-process
                 browser, all the tabs may crash because this one malfunctioned tab. Kernel-level threads would reside
                 inside one same process, resulting in an entire crash of the browser.

  * Cons:
  - Memory bloat: Lots of tabs lead to many running processes, which consume a lot more memory compared to using threads

  - CPU overhead: Different processes associated with the browser need to communicate with each other,
                  and such communication is much slower than that done by threads that use shared memory. Because
                  processes have to delegate their communication with other processes via the kernel, resulting in
                  a communicative mediator.

3. Interrupts and signals:
   a. While typing the command to the shell, the keyboard generates hardware
      interrupts via its interrupt controller, interrupting the processor which stops
      what it's currently doing, and finds the suitable OS routine to handle the interrupt
      by inspecting the interrupt vector (IDT), and jumps to it (in kernel mode).
      The OS routine reads the keys that were pressed (either directly from
      the keyboard's memory via DMA or from the interrupt request itself).

      The aforementioned OS routine determines that we've been typing to the shell (as it has
      focus) and writes the characters we've been typing to the STDIN file that
      the shell has opened and is blocking on, via the 'write' syscall.

      The shell is using 'select' to be notified of new characters that arrive to STDIN,
      and then uses 'read' to read those specific characters. This is different from just
      reading the entire STDIN file, since it doesn't have to wait for the STDIN file
      to be closed (which would only happen when we terminate the shell, not something
      we want) thus allowing the shell to be interactive.

      The shell also writes those same characters to STDOUT.

   b. Once a newline is read, the shell will send a SIGTERM signal to the selected process
      via the 'kill' system call.
      Note - kill is a shell builtin, and doesn't involve the creation of a new
      process unlike most commands.

   c. Since no special handler was specified for SIGTERM, the default signal
      handler chooses to terminate the chosen program. This causes it to
      emit SIGCHLD to its parent

4. What is the difference between `real` and `virtual` time? Give an example of using each.

   Virtual time is the time spent by the CPU executing the process's
   instructions, and doesn't include the time of the syscalls themselves
   or times during which the process was non-resident, which are included
   in real time.

   As seen in the exercise, virtual time is useful for assigning each
   user-thread a constant amount of time, that doesn't fluctuate depending on
   system load.

   Real time can be used whenever we care about the human concept of time, for
   example, in a scheduling app.

   An example that uses both times: if your program takes very
   long (real time) but a time command indicates a very low virtual time, this
   indicates that there's an IO bottleneck in the program (e.g heavy memory swapping
   when your program runs out of physical RAM).

5. Describe what the functions sigsetjmp and siglongjmp do.

   My answer goes here...